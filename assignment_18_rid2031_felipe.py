# -*- coding: utf-8 -*-
"""assignment_18_rid2031_felipe.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15DrwPRghcefCv9PwWkRNGjhdTXBjOC9J

# Assignment 18 - Portfólio Individual ML Classiﬁcação - Felipe Silva - RID 2031

# Informações Datset

- age: Idade (Anos)
- sex: Sexo (1 = Masc e 0 = Fem)
- cp: Nível de dor ( 1 a 4 )
- trestbps: Pressão sanguínea em Repouso
- chol: colesterol em mg/dl:
- fbs: Fasting Blood Sugar (Teste diabético) > 120 mg/dl
- restecg: Eletrocardiogramas em repouso (0,1 ou 2)
- thalach: Ritmo cardíaco
- exang: Exercício físico que gerou Angina
- oldpeak: Depressão de ST induzida por exercício em relação ao
repouso
- slope: Tipo de inclinação do segmento ST de pico do exercício
- ca: número de vasos sanguínios ressaltados (coloridos por
ﬂuoroscopia)
- thal: Talassemia -> 3 = normal; 6 = ﬁxed defect; 7 = reversable
defect
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy             as np
import pandas            as pd
import matplotlib.pyplot as plt
import seaborn           as sns
import sys
import warnings
import fbprophet
from google.colab                  import drive
from scipy                         import stats
from sklearn.metrics               import r2_score, mean_absolute_error, mean_squared_error
from sklearn                       import metrics
from sklearn.model_selection       import train_test_split
from sklearn.preprocessing         import MinMaxScaler
from sklearn.neighbors             import KNeighborsClassifier
from sklearn.metrics               import accuracy_score
from sklearn.linear_model          import LogisticRegression
from sklearn.tree                  import DecisionTreeClassifier
from sklearn.ensemble              import RandomForestClassifier
from sklearn.naive_bayes           import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB
from sklearn.svm                   import SVC
from sklearn.neural_network        import MLPClassifier
from sklearn.metrics               import accuracy_score, precision_score, f1_score, recall_score
from sklearn.metrics               import classification_report
from sklearn.metrics               import plot_confusion_matrix
from sklearn.metrics               import plot_roc_curve
from sklearn.model_selection       import GridSearchCV
# %matplotlib inline

drive.mount('/content/gdrive', force_remount=True)

link  = '/content/gdrive/MyDrive/Colab Notebooks/Slot6 - Deliverable/heart.csv'
df    = pd.read_csv(link)
df_save = df.copy()

df.shape

df.head(5)

df.value_counts()

sns.pairplot(df)

corrMatPd = df.corr()
corrMatPd

df.describe().transpose()

df.info()

df.isnull().sum()

sns.countplot(df['target'])

f = plt.figure(figsize=(20,4))
f.add_subplot(1,2,1)
sns.distplot(df['age'])
f.add_subplot(1,2,2)
sns.boxplot(df['age'])

f = plt.figure(figsize=(20,4))
f.add_subplot(1,3,1)
df['sex'].value_counts().plot(kind='bar', color='red')
f.add_subplot(1,3,2)
df['cp'].value_counts().plot(kind='bar', color='green')
f.add_subplot(1,3,3)
sns.countplot(df['fbs'], color='yellow')

f = plt.figure(figsize=(20,4))
f.add_subplot(1,2,1)
sns.distplot(df['trestbps'])
f.add_subplot(1,2,2)
sns.boxplot(df['trestbps'])



"""# Preparando os Dados para Aplicação de ML de Classificação"""

X = df.drop(columns=["target"])
Y = df["target"]

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=7)
print(f"Shape X_train: {X_train.shape}")
print(f"Shape y_train: {y_train.shape}")
print(f"Shape X_test: {X_test.shape}")
print(f"Shape y_test: {y_test.shape}")

scaler = MinMaxScaler()
scaler.fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)
X_train = pd.DataFrame(X_train_scaled,columns = X_train.columns)
X_test = pd.DataFrame(X_test_scaled,columns = X_test.columns)

f1score_list    = []
accuracy_list   = []
recall_list     = []
precission_list = []
clf_list        = []

"""# Classificador KNN"""

scores_list = []
K_neighbors = range(1,20)

for k in K_neighbors:

  knn =  KNeighborsClassifier(n_neighbors=k)
  knn.fit(X_train, y_train)
  y_pred = knn.predict(X_test)
  scores_list.append(accuracy_score(y_test, y_pred))

plt.plot(K_neighbors, scores_list)
plt.xlabel("Valor de K")
plt.ylabel("Acurácia")

clf = KNeighborsClassifier(n_neighbors=5)
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)

accuracy  = accuracy_score(y_test, y_pred)*100
precision = precision_score(y_test, y_pred)*100
recall    = recall_score(y_test, y_pred)*100
f1score   = f1_score(y_test, y_pred)*100
f1score_list.append(accuracy)
accuracy_list.append(precision)
recall_list.append(recall)
precission_list.append(f1score)
clf_list.append('KNeighborsClassifier')
print(f"Acccuracy: {accuracy}%")
print(f"Precision: {precision}%")
print(f"Recall: {recall}%")
print(f"F1: {f1score}%")

print(classification_report(y_test, y_pred))

plot_confusion_matrix(clf, X_test, y_test, display_labels=["Yes", "No"], values_format='d')
plt.grid(False)
plt.show()

plot_roc_curve(clf, X_test, y_test)
plt.show()

"""# Classificador Regressão Logística"""

clf = LogisticRegression()
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)

accuracy  = accuracy_score(y_test, y_pred)*100
precision = precision_score(y_test, y_pred)*100
recall    = recall_score(y_test, y_pred)*100
f1score   = f1_score(y_test, y_pred)*100
f1score_list.append(accuracy)
accuracy_list.append(precision)
recall_list.append(recall)
precission_list.append(f1score)
clf_list.append('LogisticRegression')
print(f"Acccuracy: {accuracy}%")
print(f"Precision: {precision}%")
print(f"Recall: {recall}%")
print(f"F1: {f1score}%")

print(classification_report(y_test, y_pred))

plot_confusion_matrix(clf, X_test, y_test, display_labels=["Yes", "No"], values_format='d')
plt.grid(False)
plt.show()

plot_roc_curve(clf, X_test, y_test)
plt.show()

"""# Classificador Decision Tree"""

clf = DecisionTreeClassifier(criterion="entropy")
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)

accuracy  = accuracy_score(y_test, y_pred)*100
precision = precision_score(y_test, y_pred)*100
recall    = recall_score(y_test, y_pred)*100
f1score   = f1_score(y_test, y_pred)*100
f1score_list.append(accuracy)
accuracy_list.append(precision)
recall_list.append(recall)
precission_list.append(f1score)
clf_list.append('DecisionTreeClassifier')
print(f"Acccuracy: {accuracy}%")
print(f"Precision: {precision}%")
print(f"Recall: {recall}%")
print(f"F1: {f1score}%")

print(classification_report(y_test, y_pred))

plot_confusion_matrix(clf, X_test, y_test, display_labels=["Yes", "No"], values_format='d')
plt.grid(False)
plt.show()

plot_roc_curve(clf, X_test, y_test)
plt.show()

"""# Classificador Random Forest"""

clf = RandomForestClassifier(criterion='entropy', n_estimators=150) 
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)

accuracy  = accuracy_score(y_test, y_pred)*100
precision = precision_score(y_test, y_pred)*100
recall    = recall_score(y_test, y_pred)*100
f1score   = f1_score(y_test, y_pred)*100
f1score_list.append(accuracy)
accuracy_list.append(precision)
recall_list.append(recall)
precission_list.append(f1score)
clf_list.append('RandomForestClassifier')
print(f"Acccuracy: {accuracy}%")
print(f"Precision: {precision}%")
print(f"Recall: {recall}%")
print(f"F1: {f1score}%")

print(classification_report(y_test, y_pred))

plot_confusion_matrix(clf, X_test, y_test, display_labels=["Yes", "No"], values_format='d')
plt.grid(False)
plt.show()

plot_roc_curve(clf, X_test, y_test)
plt.show()

"""# Classificador Naive Bayes"""

clf = GaussianNB()
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)

accuracy  = accuracy_score(y_test, y_pred)*100
precision = precision_score(y_test, y_pred)*100
recall    = recall_score(y_test, y_pred)*100
f1score   = f1_score(y_test, y_pred)*100
f1score_list.append(accuracy)
accuracy_list.append(precision)
recall_list.append(recall)
precission_list.append(f1score)
clf_list.append('GaussianNB')
print(f"Acccuracy: {accuracy}%")
print(f"Precision: {precision}%")
print(f"Recall: {recall}%")
print(f"F1: {f1score}%")

print(classification_report(y_test, y_pred))

plot_confusion_matrix(clf, X_test, y_test, display_labels=["Yes", "No"], values_format='d')
plt.grid(False)
plt.show()

plot_roc_curve(clf, X_test, y_test)
plt.show()

clf = MultinomialNB()
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)

accuracy  = accuracy_score(y_test, y_pred)*100
precision = precision_score(y_test, y_pred)*100
recall    = recall_score(y_test, y_pred)*100
f1score   = f1_score(y_test, y_pred)*100
f1score_list.append(accuracy)
accuracy_list.append(precision)
recall_list.append(recall)
precission_list.append(f1score)
clf_list.append('MultinomialNB')
print(f"Acccuracy: {accuracy}%")
print(f"Precision: {precision}%")
print(f"Recall: {recall}%")
print(f"F1: {f1score}%")

print(classification_report(y_test, y_pred))

plot_confusion_matrix(clf, X_test, y_test, display_labels=["Yes", "No"], values_format='d')
plt.grid(False)
plt.show()

plot_roc_curve(clf, X_test, y_test)
plt.show()

clf = ComplementNB()
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)

accuracy  = accuracy_score(y_test, y_pred)*100
precision = precision_score(y_test, y_pred)*100
recall    = recall_score(y_test, y_pred)*100
f1score   = f1_score(y_test, y_pred)*100
f1score_list.append(accuracy)
accuracy_list.append(precision)
recall_list.append(recall)
precission_list.append(f1score)
clf_list.append('ComplementNB')
print(f"Acccuracy: {accuracy}%")
print(f"Precision: {precision}%")
print(f"Recall: {recall}%")
print(f"F1: {f1score}%")

print(classification_report(y_test, y_pred))

plot_confusion_matrix(clf, X_test, y_test, display_labels=["Yes", "No"], values_format='d')
plt.grid(False)
plt.show()

plot_roc_curve(clf, X_test, y_test)
plt.show()

clf = BernoulliNB()
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)

accuracy  = accuracy_score(y_test, y_pred)*100
precision = precision_score(y_test, y_pred)*100
recall    = recall_score(y_test, y_pred)*100
f1score   = f1_score(y_test, y_pred)*100
f1score_list.append(accuracy)
accuracy_list.append(precision)
recall_list.append(recall)
precission_list.append(f1score)
clf_list.append('BernoulliNB')
print(f"Acccuracy: {accuracy}%")
print(f"Precision: {precision}%")
print(f"Recall: {recall}%")
print(f"F1: {f1score}%")

print(classification_report(y_test, y_pred))

plot_confusion_matrix(clf, X_test, y_test, display_labels=["Yes", "No"], values_format='d')
plt.grid(False)
plt.show()

plot_roc_curve(clf, X_test, y_test)
plt.show()

"""# Classificador SVM"""

clf = SVC(kernel='poly')
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)

accuracy  = accuracy_score(y_test, y_pred)*100
precision = precision_score(y_test, y_pred)*100
recall    = recall_score(y_test, y_pred)*100
f1score   = f1_score(y_test, y_pred)*100
f1score_list.append(accuracy)
accuracy_list.append(precision)
recall_list.append(recall)
precission_list.append(f1score)
clf_list.append('SVM')
print(f"Acccuracy: {accuracy}%")
print(f"Precision: {precision}%")
print(f"Recall: {recall}%")
print(f"F1: {f1score}%")

print(classification_report(y_test, y_pred))

plot_confusion_matrix(clf, X_test, y_test, display_labels=["Yes", "No"], values_format='d')
plt.grid(False)
plt.show()

plot_roc_curve(clf, X_test, y_test)
plt.show()

"""# Classificador MLP"""

clf = MLPClassifier(hidden_layer_sizes=(100, 50, 20),activation='relu')
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)

accuracy  = accuracy_score(y_test, y_pred)*100
precision = precision_score(y_test, y_pred)*100
recall    = recall_score(y_test, y_pred)*100
f1score   = f1_score(y_test, y_pred)*100
f1score_list.append(accuracy)
accuracy_list.append(precision)
recall_list.append(recall)
precission_list.append(f1score)
clf_list.append('MLPClassifier')
print(f"Acccuracy: {accuracy}%")
print(f"Precision: {precision}%")
print(f"Recall: {recall}%")
print(f"F1: {f1score}%")

print(classification_report(y_test, y_pred))

plot_confusion_matrix(clf, X_test, y_test, display_labels=["Yes", "No"], values_format='d')
plt.grid(False)
plt.show()

plot_roc_curve(clf, X_test, y_test)
plt.show()

"""# Avaliando Métricas"""

df_metricas = pd.DataFrame({'Classificador': clf_list, 'F1-Score': f1score_list, 'Accuracy': accuracy_list, 'Recall': recall_list, 'Precission': precission_list})

df_metricas.sort_values(by='F1-Score', ascending=False)

"""# Tunning Modelo"""

#List Hyperparameters that we want to tune.
leaf_size = list(range(1,50))
n_neighbors = list(range(1,30))
p=[1,2]
#Convert to dictionary
hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)
#Create new KNN object
knn_2 = KNeighborsClassifier()
#Use GridSearch
clf = GridSearchCV(knn_2, hyperparameters, cv=10)
#Fit the model
best_model = clf.fit(X,Y)
#Print The value of best Hyperparameters
print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])
print('Best p:', best_model.best_estimator_.get_params()['p'])
print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])

"""# Redução de Dimensionalidade"""

from sklearn.decomposition import PCA
pca = PCA(n_components=2)

X = df.drop(columns=["target"])
Y = df["target"]
X_PCA = pca.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_PCA, Y, test_size=0.2, random_state=7)
print(f"Shape X_train: {X_train.shape}")
print(f"Shape y_train: {y_train.shape}")
print(f"Shape X_test: {X_test.shape}")
print(f"Shape y_test: {y_test.shape}")

sns.scatterplot(x=X_PCA[:,0], y=X_PCA[:,1], hue=Y)

f1score_list    = []
accuracy_list   = []
recall_list     = []
precission_list = []
clf_list        = []

"""## Classificador Decision TRee"""

clf = DecisionTreeClassifier(criterion="entropy")
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)

accuracy  = accuracy_score(y_test, y_pred)*100
precision = precision_score(y_test, y_pred)*100
recall    = recall_score(y_test, y_pred)*100
f1score   = f1_score(y_test, y_pred)*100
f1score_list.append(accuracy)
accuracy_list.append(precision)
recall_list.append(recall)
precission_list.append(f1score)
clf_list.append('DecisionTreeClassifier')
print(f"Acccuracy: {accuracy}%")
print(f"Precision: {precision}%")
print(f"Recall: {recall}%")
print(f"F1: {f1score}%")

print(classification_report(y_test, y_pred))

plot_confusion_matrix(clf, X_test, y_test, display_labels=["Yes", "No"], values_format='d')
plt.grid(False)
plt.show()

plot_roc_curve(clf, X_test, y_test)
plt.show()

"""## Classificador SVM com Kernel Linear"""

clf = SVC(kernel='linear')
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)

accuracy  = accuracy_score(y_test, y_pred)*100
precision = precision_score(y_test, y_pred)*100
recall    = recall_score(y_test, y_pred)*100
f1score   = f1_score(y_test, y_pred)*100
f1score_list.append(accuracy)
accuracy_list.append(precision)
recall_list.append(recall)
precission_list.append(f1score)
clf_list.append('SVM Linear')
print(f"Acccuracy: {accuracy}%")
print(f"Precision: {precision}%")
print(f"Recall: {recall}%")
print(f"F1: {f1score}%")

print(classification_report(y_test, y_pred))

plot_confusion_matrix(clf, X_test, y_test, display_labels=["Yes", "No"], values_format='d')
plt.grid(False)
plt.show()

plot_roc_curve(clf, X_test, y_test)
plt.show()

"""## Classificador SVM com Kernel Polinomial"""

clf = SVC(kernel='poly')
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)

accuracy  = accuracy_score(y_test, y_pred)*100
precision = precision_score(y_test, y_pred)*100
recall    = recall_score(y_test, y_pred)*100
f1score   = f1_score(y_test, y_pred)*100
f1score_list.append(accuracy)
accuracy_list.append(precision)
recall_list.append(recall)
precission_list.append(f1score)
clf_list.append('SVM Polinomial')
print(f"Acccuracy: {accuracy}%")
print(f"Precision: {precision}%")
print(f"Recall: {recall}%")
print(f"F1: {f1score}%")

print(classification_report(y_test, y_pred))

plot_confusion_matrix(clf, X_test, y_test, display_labels=["Yes", "No"], values_format='d')
plt.grid(False)
plt.show()

plot_roc_curve(clf, X_test, y_test)
plt.show()

"""## Classificador MLP"""

clf = MLPClassifier(hidden_layer_sizes=(100, 50, 20),activation='relu')
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)

accuracy  = accuracy_score(y_test, y_pred)*100
precision = precision_score(y_test, y_pred)*100
recall    = recall_score(y_test, y_pred)*100
f1score   = f1_score(y_test, y_pred)*100
f1score_list.append(accuracy)
accuracy_list.append(precision)
recall_list.append(recall)
precission_list.append(f1score)
clf_list.append('MLPClassifier')
print(f"Acccuracy: {accuracy}%")
print(f"Precision: {precision}%")
print(f"Recall: {recall}%")
print(f"F1: {f1score}%")

print(classification_report(y_test, y_pred))

plot_confusion_matrix(clf, X_test, y_test, display_labels=["Yes", "No"], values_format='d')
plt.grid(False)
plt.show()

plot_roc_curve(clf, X_test, y_test)
plt.show()

"""## Avaliação de Métricas"""

df_metricas = pd.DataFrame({'Classificador': clf_list, 'F1-Score': f1score_list, 'Accuracy': accuracy_list, 'Recall': recall_list, 'Precission': precission_list})

df_metricas.sort_values(by='F1-Score', ascending=False)